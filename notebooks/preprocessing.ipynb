{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/40536560/ipython-and-jupyter-autocomplete-not-working\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, format='',\n",
    "                level=logging.INFO, datefmt=None)\n",
    "logger = logging.getLogger('preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global\n",
    "# variables\n",
    "TARGET = 'sales'\n",
    "TIME_HORIZON = 28\n",
    "END_TRAIN = 1941 - 28  # total num of days is 1941, leave the last 28 out for testing purposes\n",
    "DAY_COLUMN = 'd'\n",
    "\n",
    "# load data\n",
    "logger.info('Load Main Data')\n",
    "DATA_PATH = Path('../data')\n",
    "calendar_df = pd.read_csv(DATA_PATH / 'dataset/calendar.csv')\n",
    "train_df = pd.read_csv(DATA_PATH / 'dataset/sales_train_evaluation.csv')\n",
    "prices_df = pd.read_csv(DATA_PATH / 'dataset/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat train_df\n",
    "# instead of days in a horizontal orientation, make it vertical\n",
    "index_columns = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "grid_df = pd.melt(train_df,\n",
    "                  id_vars=index_columns,\n",
    "                  var_name=DAY_COLUMN,\n",
    "                  value_name='sales')\n",
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.d[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(grid_df.d != 'id').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Holdout validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_training_day = END_TRAIN\n",
    "end_val_day = END_TRAIN + TIME_HORIZON\n",
    "\n",
    "mask = grid_df.d != 'id'\n",
    "grid_df = grid_df[mask]\n",
    "del mask\n",
    "grid_df['d'] = grid_df['d'].apply(lambda x: x[2:]).astype(np.int16)\n",
    "holdout_df = grid_df[(grid_df['d'] > last_training_day) & (grid_df['d'] <= end_val_day)][index_columns + [DAY_COLUMN, TARGET]]\n",
    "grid_df = grid_df[grid_df['d'] <= last_training_day]\n",
    "\n",
    "holdout_df.reset_index(drop=True, inplace=True)\n",
    "holdout_df['d'] = holdout_df['d'].apply(lambda x: 'd_' + str(x))\n",
    "grid_df['d'] = grid_df['d'].apply(lambda x: 'd_' + str(x))\n",
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rows for test (not sure if needed)\n",
    "logger.info('Adding test days')\n",
    "add_grid = pd.DataFrame()\n",
    "for i in range(1, TIME_HORIZON + 1):\n",
    "    temp_df = train_df[index_columns]\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    temp_df['d'] = 'd_' + str(END_TRAIN + i)\n",
    "    temp_df[TARGET] = np.nan\n",
    "    add_grid = pd.concat([add_grid, temp_df])\n",
    "\n",
    "grid_df = pd.concat([grid_df, add_grid])\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "# print(grid_df.tail())\n",
    "del temp_df, add_grid, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release dates\n",
    "logger.info('Release')\n",
    "release_df = prices_df.groupby(['store_id', 'item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n",
    "release_df.columns = ['store_id', 'item_id', 'release']\n",
    "# print(release_df.head())\n",
    "\n",
    "grid_df = merge_by_concat(grid_df, release_df, ['store_id', 'item_id'])  # match release date w each product (store_id, item_id)\n",
    "# print(grid_df.head(20))\n",
    "idx = calendar_df.index.values.tolist()\n",
    "d = ['d_' + str(x + 1) for x in idx]\n",
    "calendar_df['d'] = d\n",
    "# print(calendar_df.head())\n",
    "grid_df = merge_by_concat(grid_df, calendar_df[['wm_yr_wk', 'd']], ['d'])  # match day number w wm_yr_wk\n",
    "# print(grid_df.head(20))\n",
    "grid_df = grid_df[grid_df['wm_yr_wk'] >= grid_df['release']].reset_index(drop=True)  # for each product only keep if day is after release date -> delete useless rows\n",
    "# print(grid_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calendar_cols = ['date', 'd', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "calendar_cols = ['date', 'd']\n",
    "grid_df = grid_df.merge(calendar_df[calendar_cols], on=\"d\", how=\"left\")\n",
    "holdout_df = holdout_df.merge(calendar_df[calendar_cols], on=\"d\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.info()\n",
    "grid_df.head()\n",
    "grid_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df.info()\n",
    "holdout_df.head()\n",
    "holdout_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df.to_csv(f'{DATA_PATH}/holdout.csv')\n",
    "grid_df.to_csv(f'{DATA_PATH}/preprocessed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
